Seattle area residents use the 'Find It, Fix It' (FIFI) mobile app to report non-emergency problems to the City, _e.g._ graffiti, broken streetlights, and etc. This project includes: data exploration, statistical analysis, and classification models, using NLP and image classification.  

### Project Objective
To assist the City by training a classification filter based on the image and text data contained in each FIFI request. Using both text and image data is important because the data is very noisy and some of the class categories are difficult to separate due to the overlap between request categories.  

### About the Data
The data was generated by the FIFI mobile app produced by the City of Seattle's Customer Service Bureau. The data was requested through a public information request form on the [City Public Disclosure site](http://www.seattle.gov/public-records). All reports include text, and most include photos.  

![fifi app home screen](images/fifi_app_home_screen.png)  

### Project Challenges
• Ambiguous Classes: overlapping categories, with imbalanced categorical data  
• Noisy Data: incomplete, incorrectly labeled, and duplicate data  
• Data Volume: Scale of image data (> 50 GB)  

### Project Results
Due to the high degree of ambiguity between classes, some categories performed better than others. For example, the text classifier accurately identifies Graffiti and Garbage category instances, but tends to incorrectly label Abandoned Vehicle and Parking instances. This is understandable since those categories are closely related.  
The fastText model performed slightly worse than the best RNN models. However, fastText only took about 30 minutes to train on 152,820 text samples instead of the 10 hours for the RNN.  
